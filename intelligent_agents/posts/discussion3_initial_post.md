## Collaborative Discussion 3: Deep Learning (Initial Post)


The emergence of generative deep learning tools, such as DALL·E for image creation and ChatGPT for text generation, has led to a new wave of content creation. However, these technologies raise several ethical issues related to ownership, misinformation, and algorithmic bias.

One primary concern is the blurring of authorship and intellectual property rights. Generative models are often trained on large datasets sourced from the internet, including copyrighted artworks. For example, users have prompted image generation tools to produce content in the style of Studio Ghibli, an animation studio known for its distinct artistic identity, without the studio’s consent. Although the resulting images are technically “new,” they mimic recognisable artistic traits, raising ethical and legal concerns over the use of copyrighted material in training data (O’Brien and Parvini, 2025).

Another risk lies in the potential misuse of generative models to produce misleading or harmful content. Deepfakes and AI-generated misinformation can easily be weaponised in political, social, or economic contexts (Floridi and Chiriatti, 2020). Additionally, deep learning systems may reproduce social biases present in their training data. Without careful oversight, these tools can reinforce stereotypes or exclude minority perspectives, thereby contributing to digital inequality (Weidinger et al., 2021).

In conclusion, while generative AI presents exciting possibilities, its use must be governed by ethical principles that prioritise consent, fairness, and accountability.



**References**

Floridi, L. and Chiriatti, M. (2020) ‘GPT-3: Its nature, scope, limits, and consequences’, Minds and machines, 30(4), pp. 681–694.

O’Brien, M. and Parvini, S. (2025) ChatGPT’s viral Studio Ghibli-style images highlight AI copyright concerns, AP News. Available at: https://apnews.com/article/studio-ghibli-chatgpt-images-hayao-miyazaki-openai-0f4cb487ec3042dd5b43ad47879b91f4 (Accessed: 18 April 2025).

Weidinger, L. et al. (2021) ‘Ethical and social risks of harm from Language Models’, arXiv [cs.CL]. Available at: http://arxiv.org/abs/2112.04359.

