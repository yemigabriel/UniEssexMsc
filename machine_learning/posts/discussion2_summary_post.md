## Collaborative Discussion 2: Summary Post  

In my initial post, I explored the benefits and risks - both ethical and legal - associated with Artificial Intelligence (AI) writers powered by Artificial Neural Networks (ANNs). Engaging with my peers’ posts has enriched the discussion as additional risks and benefits were highlighted. This summary post will discuss potential measures to mitigate risks linked to AI writing and advocate for responsible AI use.

One of the primary risks discussed is the potential for bias in generated content. Solving this requires prioritising diverse and representative training datasets using data preprocessing techniques like oversampling, undersampling, or data augmentation (Ferrara, 2024). This way, the neural networks can produce more balanced, nuanced outputs. Additionally, implementing bias-detecting algorithms can help detect and adjust biased patterns that may arise while training the neural network. Adversarial debiasing is a technique that can be used to look out for biases in the over-representation of some viewpoints or stereotypes (Zhang et al.,2018). With this technique, a secondary model provides feedback during the training of the ANN and prompts adjustments to the weights of the ANN to reduce biased outputs.

Organisations should also adopt techniques like explainable AI (XAI) to improve transparency (Saeed and Omlin, 2023). Guidelines for responsible AI use must be established to ensure that generated content is not misleading or harmful. Organisations must engage with ethicists and other stakeholders to develop ethical frameworks that guide the deployment of AI tools. Frequent audits and reviews can help maintain compliance with these guidelines.

Finally, educating users about the capabilities and limitations of AI writers will help them evaluate AI-generated content more critically (Tiernan et al., 2023). By understanding potential risks, users can make informed decisions about the information they share or consume. In conclusion, prioritising diverse training datasets, enhancing transparency, establishing ethical guidelines, and promoting digital literacy will combat the misuse of AI writers.


**References**

Ferrara, E. (2024) ‘Fairness and Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, and Mitigation Strategies’, Sci, 6(1). doi: 10.3390/sci6010003.

Saeed, W. and Omlin, C. (2023) ‘Explainable AI (XAI): A systematic meta-survey of current challenges and future opportunities’, Know. -Based Syst. NLD: Elsevier Science Publishers B. V., 263(C). doi: 10.1016/j.knosys.2023.110273.

Tiernan, P. et al. (2023) ‘Information and Media Literacy in the Age of AI: Options for the Future’, Education sciences, 13(9). doi: 10.3390/educsci13090906.

Zhang, B. H., Lemoine, B. and Mitchell, M. (2018) ‘Mitigating Unwanted Biases with Adversarial Learning’, in Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. New York, NY, USA: Association for Computing Machinery (AIES ’18), pp. 335–340.
