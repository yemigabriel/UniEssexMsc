## **Research Proposal Review**

### **Explainable AI for Breast Cancer Diagnosis in Nigeria: Accuracy, Trust, and Mobile Integration**


---


**1\. Preferred Research Method: Mixed Methods**

Given the nature of the project, a mixed methods research approach would be most appropriate. The quantitative component will involve model development, performance evaluation, and statistical analysis of medical image classification accuracy. The qualitative aspect will focus on clinician perceptions, trust, and usability of explainable AI tools â€” particularly in the Nigerian healthcare context.

Mixed methods are ideal for this project as they allow for both the technical validation of AI models and the human-centred evaluation of their interpretability and adoption potential in real-world settings.

**2\. Data Collection Methods**

* **Quantitative**:

  * Medical imaging datasets (e.g., mammogram scans from open-access repositories or local Nigerian health institutions)

  * Model training and evaluation metrics (e.g., accuracy, AUC, precision-recall, and explainability outputs using tools like Grad-CAM or SHAP)

* **Qualitative**:

  * Interviews or surveys with radiologists and healthcare professionals on their attitudes towards AI-driven decision support

  * Thematic analysis of clinician feedback on interpretability, usability, and trust

**3\. Skills Required and To Be Developed**

* **Technical Skills**:

  * Python programming, deep learning frameworks (TensorFlow, Keras)

  * Implementing and evaluating XAI methods (Grad-CAM, SHAP)

  * Statistical analysis and performance evaluation

* **Research Skills**:

  * Designing and conducting qualitative interviews or surveys

  * Thematic coding and analysis of qualitative data

  * Ethical considerations in working with health data and professionals

* **Communication & Reporting**:

  * Translating technical findings into accessible reports for non-technical stakeholders

  * Visualising and presenting results clearly, especially explainability outputs

